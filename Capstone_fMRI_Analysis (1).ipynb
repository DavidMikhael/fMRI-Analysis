{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#imports packages\n",
        "\n",
        "import keras\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from google.colab import drive\n",
        "from nilearn import datasets\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "from nilearn import image\n",
        "from nilearn.regions import RegionExtractor\n",
        "from nilearn import plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from nilearn import decomposition\n",
        "import pandas as pd\n",
        "import os\n",
        "from nilearn.image import mean_img, index_img\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "!pip install nilearn"
      ],
      "metadata": {
        "id": "TsKGEsuo2fM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p2qEUXGAP7O"
      },
      "outputs": [],
      "source": [
        "#mounts the google drive to read from it\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr240xflQsH3"
      },
      "outputs": [],
      "source": [
        "#reads the adhd_200 data sample from nilearn\n",
        "\n",
        "num = 40\n",
        "adhd_data = datasets.fetch_adhd(n_subjects=num) #reads the fMRI dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracts the phenotypic data from the sample dataset\n",
        "\n",
        "dataa = adhd_data.phenotypic\n",
        "dataa = pd.DataFrame(dataa)"
      ],
      "metadata": {
        "id": "TMKmR9VCY0dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB0FvTTsBHpP"
      },
      "outputs": [],
      "source": [
        "#gets the ohsu data from the drive\n",
        "\n",
        "DIR = \"drive/MyDrive/fmri_ohsu\"\n",
        "\n",
        "ohsu = [DIR + \"/\" + entry for entry in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, entry))]\n",
        "ohsu = ohsu[1:]\n",
        "\n",
        "ohsuu = []\n",
        "for i in range(len(ohsu)):\n",
        "  if ohsu[i].split(\"_\")[-1].split(\".\")[0] == 'run1':\n",
        "    ohsuu.append(ohsu[i])\n",
        "\n",
        "print(len(ohsuu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5AjS3aFCMYG"
      },
      "outputs": [],
      "source": [
        "#gets the neuroimage data from the drive\n",
        "\n",
        "DIR = \"drive/MyDrive/fmri_neuroimage\"\n",
        "\n",
        "neuroimage = [DIR + \"/\" + entry for entry in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, entry))]\n",
        "print(len(neuroimage))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_UgsisECSdI"
      },
      "outputs": [],
      "source": [
        "#gets the pittsburgh data from the drive\n",
        "\n",
        "DIR = \"drive/MyDrive/fmri-pittsburgh\"\n",
        "\n",
        "pittsburgh = [DIR + \"/\" + entry for entry in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, entry))]\n",
        "print(len(pittsburgh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX7KTmGHCdkF"
      },
      "outputs": [],
      "source": [
        "#gets the peking data from the drive\n",
        "\n",
        "DIR = \"drive/MyDrive/fmri_peking\"\n",
        "\n",
        "peking = [DIR + \"/\" + entry for entry in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, entry))]\n",
        "print(len(peking))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf17CGobvZdY"
      },
      "outputs": [],
      "source": [
        "#combines the multiple sites functional data\n",
        "\n",
        "func = ohsuu + neuroimage + peking\n",
        "print(len(func))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50PjUtlavhrF"
      },
      "outputs": [],
      "source": [
        "#extracts subject IDs\n",
        "IDs = []\n",
        "\n",
        "for i in range(len(func)):\n",
        "  IDs.append(np.int64(func[i].split(\"_\")[3]))\n",
        "\n",
        "#sorts the subject IDs to match subjects later\n",
        "IDs_sort = sorted(IDs)\n",
        "\n",
        "#stores functional data in a new list with the new IDs order\n",
        "funcy = []\n",
        "for elem in IDs_sort:\n",
        "  for i in range(len(IDs_sort)):\n",
        "    if np.int64(func[i].split(\"_\")[3]) == elem:\n",
        "      funcy.append(func[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stores the IDs from the new list to check matching later\n",
        "IsDs = []\n",
        "\n",
        "for i in range(len(funcy)):\n",
        "  IsDs.append(np.int64(funcy[i].split(\"_\")[3]))"
      ],
      "metadata": {
        "id": "4Nku7vZqnNWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2FkdTVzvm8I"
      },
      "source": [
        "Pheno tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mblMWbCHED4C"
      },
      "outputs": [],
      "source": [
        "#gets the ohsu phenotypic data from the drive\n",
        "\n",
        "site_ohsu = int(pheno[pheno[\"ScanDir ID\"] == 1084283][\"Site\"])\n",
        "\n",
        "pheno_ohsu = pheno[pheno[\"Site\"] == site_ohsu]\n",
        "\n",
        "pheno_ohsu = pheno_ohsu.reset_index()\n",
        "\n",
        "print(len(pheno_ohsu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SAhcwuKErNH"
      },
      "outputs": [],
      "source": [
        "#gets the neuroimage phenotypic data from the drive\n",
        "\n",
        "site_neuroimage = int(pheno[pheno[\"ScanDir ID\"] == 1017176][\"Site\"])\n",
        "\n",
        "pheno_neuroimage = pheno[pheno[\"Site\"] == site_neuroimage]\n",
        "\n",
        "pheno_neuroimage = pheno_neuroimage.reset_index()\n",
        "\n",
        "len(pheno_neuroimage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8LVT5mSFnjR"
      },
      "outputs": [],
      "source": [
        "#gets the peking phenotypic data from the drive\n",
        "\n",
        "site_peking = int(pheno[pheno[\"ScanDir ID\"] == 1050345][\"Site\"])\n",
        "\n",
        "pheno_peking = pheno[pheno[\"Site\"] == site_peking]\n",
        "\n",
        "pheno_peking = pheno_peking.reset_index()\n",
        "\n",
        "len(pheno_peking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmGnSRLCoDHQ"
      },
      "outputs": [],
      "source": [
        "#combines the multiple sites phenotypic data\n",
        "\n",
        "diag = pd.concat([pheno_ohsu, pheno_neuroimage, pheno_peking], axis = 0)\n",
        "\n",
        "diag = diag.reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu39WoxjvqjX"
      },
      "source": [
        "Matching them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a2A4m2qyHr0"
      },
      "outputs": [],
      "source": [
        "#matches subject IDs of functional and phenotypic data\n",
        "df_pheno = pd.DataFrame()\n",
        "\n",
        "for elem in IDs_sort:\n",
        "  for i in range(len(diag)):\n",
        "    if diag.loc[i,\"ScanDir ID\"] == elem:\n",
        "      df_pheno = df_pheno.append(diag.iloc[i,:], ignore_index = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IDs_match = []\n",
        "for i in list(df_pheno[\"ScanDir ID\"]):\n",
        "  IDs_match.append(int(i))\n",
        "\n",
        "#checks that IDs match\n",
        "IDs_match == IsDs"
      ],
      "metadata": {
        "id": "G73jCSEOkTt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gets the phenotypic data of just the peking university data as a subset (ordered)\n",
        "\n",
        "pekingy = df_pheno[df_pheno[\"Site\"] == 1].index\n",
        "\n",
        "pekingy = np.array(pekingy)\n",
        "\n",
        "pekingy_pheno = df_pheno[df_pheno[\"Site\"] == 1]"
      ],
      "metadata": {
        "id": "6Fq8gNffm8b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converts to numeric to work with later\n",
        "df_pheno[\"Verbal IQ\"] = df_pheno[\"Verbal IQ\"].apply(pd.to_numeric, errors='coerce')\n",
        "df_pheno[\"Performance IQ\"] = df_pheno[\"Performance IQ\"].apply(pd.to_numeric, errors='coerce')\n",
        "df_pheno[\"Full4 IQ\"] = df_pheno[\"Full4 IQ\"].apply(pd.to_numeric, errors='coerce')\n",
        "df_pheno[\"Handedness\"] = df_pheno[\"Handedness\"].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "#stores only the performance (visuospatial) IQ for later purposes\n",
        "phenotypic = df_pheno[[\"Performance IQ\"]]\n",
        "phenotypic = np.array(phenotypic)"
      ],
      "metadata": {
        "id": "bMo6AzLHsPlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMxpz7-qIMZa"
      },
      "outputs": [],
      "source": [
        "#gets the diagnosis labels, and merge all 3 ADHD subsets to one (ADHD vs not)\n",
        "\n",
        "y = np.array(df_pheno[\"DX\"])\n",
        "\n",
        "for i in range(len(y)):\n",
        "  if y[i] == \"1\" or y[i] == \"2\" or y[i] == \"3\":\n",
        "    y[i] = \"1\"\n",
        "\n",
        "y = y.astype(int)\n",
        "\n",
        "print(len(y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gets the diagnosis data of just the peking site data as a subset (ordered)\n",
        "\n",
        "y_peking = y[np.ix_(list(pekingy))]\n",
        "\n",
        "print(len(y_peking))"
      ],
      "metadata": {
        "id": "dHucLyC_n3UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6VBtdsiSSak"
      },
      "source": [
        "DictLearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code below from nilearn documentation https://nilearn.github.io/stable/index.html\n"
      ],
      "metadata": {
        "id": "sSIUmCYSWEj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QBVOU8nHA--"
      },
      "outputs": [],
      "source": [
        "from nilearn.decomposition import DictLearning\n",
        "\n",
        "# Initialize DictLearning object\n",
        "dict_learn = DictLearning(n_components=8, smoothing_fwhm=6.,\n",
        "                          memory=\"nilearn_cache\", memory_level=2,\n",
        "                          random_state=0)\n",
        "# Fit to the data\n",
        "dict_learn.fit(peking)\n",
        "# Resting state networks/maps in attribute `components_img_`\n",
        "components_img = dict_learn.components_img_\n",
        "\n",
        "# Visualization of functional networks\n",
        "\n",
        "plotting.plot_prob_atlas(components_img, view_type='filled_contours',\n",
        "                         title='Dictionary Learning maps')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masker = dict_learn.masker_\n",
        "data = np.concatenate(masker.transform(peking))\n",
        "scores = dict_learn._raw_score(data, per_component=True)\n",
        "plt.plot(scores, '-o')\n",
        "plt.title('Explained variance for 100 components')"
      ],
      "metadata": {
        "id": "VzHCHGocTAHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plots the extracted regions in a specific network\n",
        "\n",
        "plotting.plot_stat_map(image.index_img(components_img, 7), cut_coords = (3, 20, 36))\n",
        "plotting.show()"
      ],
      "metadata": {
        "id": "4s4iWxCX3uaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeMxN0M8Q84Q"
      },
      "outputs": [],
      "source": [
        "extractor = RegionExtractor(components_img, threshold=0.5,\n",
        "                            thresholding_strategy='ratio_n_voxels',\n",
        "                            extractor='local_regions',\n",
        "                            standardize=True, min_region_size=1350)\n",
        "extractor.fit()\n",
        "# Extracted regions are stored in regions_img_\n",
        "regions_extracted_img = extractor.regions_img_\n",
        "# Each region index is stored in index_\n",
        "regions_index = extractor.index_\n",
        "# Total number of regions extracted\n",
        "n_regions_extracted = regions_extracted_img.shape[-1]\n",
        "\n",
        "# Visualization of region extraction results\n",
        "title = ('%d regions are extracted from %d components.'\n",
        "         '\\nEach separate color of region indicates extracted region'\n",
        "         % (n_regions_extracted, 8))\n",
        "plotting.plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n",
        "                         title=title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOW7_MjNSFge"
      },
      "outputs": [],
      "source": [
        "correlations = []\n",
        "# Initializing ConnectivityMeasure object with kind='correlation'\n",
        "connectome_measure = ConnectivityMeasure(kind='correlation')\n",
        "for filename in funcy:\n",
        "    # call transform from RegionExtractor object to extract timeseries signals\n",
        "    timeseries_each_subject = extractor.transform(filename)\n",
        "    # call fit_transform from ConnectivityMeasure object\n",
        "    correlation = connectome_measure.fit_transform([timeseries_each_subject])\n",
        "    # saving each subject correlation to correlations\n",
        "    correlations.append(correlation)\n",
        "\n",
        "# Mean of all correlations\n",
        "mean_correlations = np.mean(correlations, axis=0).reshape(n_regions_extracted,\n",
        "                                                          n_regions_extracted)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this step I visually inspected the outputs and selected the indices below to correspond to my two networks of interest. I am fitting the DictLearn object to a small subset of the data because of the computationally extensive time."
      ],
      "metadata": {
        "id": "Ssi0Oq-mxFBh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZTF5tvdbXfG"
      },
      "outputs": [],
      "source": [
        "np.shape(correlations)\n",
        "\n",
        "corrs = np.array(correlations)\n",
        "\n",
        "corrs = corrs.reshape(len(func), n_regions_extracted, n_regions_extracted)\n",
        "\n",
        "DMN = np.array([10, 13, 14, 17, 32])\n",
        "ATT = np.array([37, 36, 35, 5, 8,  7, 18, 19, 20])\n",
        "DMN&ATT = np.array([10, 13, 14, 17, 32, 37, 36, 35, 5, 8,  7, 18, 19, 20])\n",
        "\n",
        "DMN_conn = corrs[np.ix_(list(range(len(func))), here, here)]\n",
        "\n",
        "ATT_conn = corrs[np.ix_(list(range(len(func))), here2, here2)]\n",
        "\n",
        "ATT_DMN_conn = corrs[np.ix_(list(range(len(func))), here_2, here_2)]\n",
        "\n",
        "# Gets the mean DMN-corresponding cells of connectivity matrix\n",
        "DMN_conn = mean_correlations[np.ix_(here, here)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeI-oW14bt7Z"
      },
      "source": [
        "ICA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaKEzMdAbuv_"
      },
      "outputs": [],
      "source": [
        "# Does ICA decomposition\n",
        "canica = decomposition.CanICA(n_components=20, mask_strategy='background')\n",
        "canica.fit(peking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jv9Vnxhbx_J"
      },
      "outputs": [],
      "source": [
        "components = canica.components_\n",
        "\n",
        "#Using a masker to project into the 3D space\n",
        "components_img = canica.masker_.inverse_transform(components)\n",
        "\n",
        "#Plotting all the components\n",
        "plotting.plot_prob_atlas(components_img, title='All ICA components')\n",
        "plotting.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiHvYorxcEVZ"
      },
      "outputs": [],
      "source": [
        "#Using a filter to extract the regions time series \n",
        "from nilearn import input_data\n",
        "masker = input_data.NiftiMapsMasker(components_img, smoothing_fwhm=6,\n",
        " standardize=False, detrend=True,\n",
        " t_r=2.5, low_pass=0.1,\n",
        " high_pass=0.01)\n",
        "#Computing the regions timeseries signals and storing them\n",
        "subjects = []\n",
        "\n",
        "for func_file in peking:\n",
        " time_series = masker.fit_transform(func_file)\n",
        " subjects.append(time_series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnP2dbZJcTXF"
      },
      "outputs": [],
      "source": [
        "#Generates correlation matrices as connectivity measures\n",
        "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
        "correlation_matrices_ICA = correlation_measure.fit_transform(subjects)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data prep\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Konu36f3c1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix(n_subjects=len(peking), rows, columns, data1, data2, data_pheno):\n",
        "  '''\n",
        "  Creates the input variables to the classifier below from the different types\n",
        "  of data avaialble\n",
        "  '''\n",
        "  X = np.zeros(shape=(n_subjects,rows,columns))\n",
        "  X[:,:np.shape(data1)[0],:np.shape(data1)[1]] = data1\n",
        "  if data2:\n",
        "    X[:,np.shape(data1)[0]:, np.shape(data1)[1]:] = data2\n",
        "  mat = []\n",
        "  for i in range(n_subjects):\n",
        "    this = X\n",
        "    matr = list(this[np.triu_indices(rows, k=1)])\n",
        "    mat.append(matr)\n",
        "  if data_pheno:\n",
        "    mat_all = np.concatenate([mat, data_pheno], axis=1)\n",
        "    return mat_all\n",
        "  else:\n",
        "    return mat\n"
      ],
      "metadata": {
        "id": "YGXRb5PuYPo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_1n3-AuHijO"
      },
      "outputs": [],
      "source": [
        "# call examples to the function\n",
        "\n",
        "predinfo = matrix(n_subjects, 25, 25, correlation_matrices_ICA, DMN_conn, None)\n",
        "\n",
        "predinfo2 = matrix(n_subjects, 29, 29, correlation_matrices_ICA, ATT_conn, None)\n",
        "\n",
        "predinfo3 = matrix(n_subjects, 29, 29, DMN_conn, None, phenotypic)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests\n",
        "\n",
        "(I tried different input data for the different predictor data combinations, and then plotted the results as in my paper)"
      ],
      "metadata": {
        "id": "uAkZz9p4wuMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cross-validation score of support vector machine\n",
        "clf = svm.SVC()\n",
        "scores = cross_val_score(clf, predinfo, y_peking, cv=7)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "zVOGuHXFfisA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross-validation score of a sequential neural network\n",
        "\n",
        "acc = []\n",
        "for i in range(7):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(predinfo, y_peking, test_size=0.3)\n",
        "\n",
        "  import keras\n",
        "  import tensorflow.keras.optimizers\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense\n",
        "  #from keras.optimizers import Adam\n",
        "  classifier = Sequential()\n",
        "  #First Hidden Layer\n",
        "  classifier.add(Dense(32, activation='tanh', kernel_initializer='random_normal', input_shape=np.shape(predinfo)[1:]))\n",
        "  #Second Hidden Layer\n",
        "  classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
        "  #Third Hidden Layer\n",
        "  classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
        "  #Output Layer\n",
        "  classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
        "  #Compiling the model\n",
        "  classifier.compile(optimizer = Adam(lr =.0001),loss='binary_crossentropy', metrics =['accuracy'])\n",
        "  #Fitting the model\n",
        "  classifier.fit(np.array(X_train),np.array(y_train), batch_size=32, epochs=100)\n",
        "  eval_model=classifier.evaluate(np.array(X_train), np.array(y_train))\n",
        "  acc.append(eval_model[1])"
      ],
      "metadata": {
        "id": "O5pmI3-e0cWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}